{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chinese graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import codecs\n",
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = codecs.open('./chinesegraph/chinese_words.csv', 'rb', encoding='utf-8')\n",
    "words = [line.strip() for line in f]\\\n",
    "print 'number of words : ', len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars = set()\n",
    "for w in words:\n",
    "    chars = chars.union(set( w ))\n",
    "    # Creating a little 'index'\n",
    "print 'number of chars : ', len(chars)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "for ch in chars:\n",
    "    G.add_node(ch,{'chinese':ch})\n",
    "\n",
    "print 'number of chars nodes : ', G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,w in enumerate(words):\n",
    "    G.add_node(str(i),{'chinese': w })\n",
    "    for ch in w:\n",
    "        G.add_edge(str(i),ch)\n",
    "\n",
    "print 'number of nodes (chars + words): ', G.number_of_nodes()\n",
    "\n",
    "nx.write_graphml(G,'chinese_graph.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import time\n",
    "from random import choice\n",
    "from math import log\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IS_CHINESE_TEST = True\n",
    "\n",
    "if IS_CHINESE_TEST:\n",
    "    G = nx.read_graphml('./data/graphs/chinese_graph.graphml', unicode) # Chinese graph\n",
    "else:\n",
    "    G = nx.read_graphml('graphs/bipartite_graph.graphml', unicode) # Korean language graph    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = nx.connected_component_subgraphs(G)\n",
    "G = next(gen)\n",
    "output_dir = \"tmpDistancesFull2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sts = nx.bipartite.sets(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = None\n",
    "hanjas = None\n",
    "wordSet = None\n",
    "\n",
    "if len(sts[0]) > 6000: \n",
    "    words = list(sts[0])\n",
    "    wordSet = sts[0]\n",
    "    hanjas = list(sts[1])\n",
    "else: \n",
    "    words = list(sts[1])\n",
    "    wordSet = sts[1]\n",
    "    hanjas = list(sts[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordic = {G.node[e]['chinese']:k for k,e in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synonyms = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open('./data/synonyms/all_chinese_synonyms.csv', 'r', encoding='utf-8') as f:\n",
    "        synonyms = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synDP = []\n",
    "randDP = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = nx.bipartite.biadjacency_matrix(G, hanjas)\n",
    "A = A.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = False # In case we chose not to do TF-IDF weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minK = 666\n",
    "maxK = 668"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U,s,V = sp.sparse.linalg.svds(A,800)\n",
    "Vtr = V.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pr in synonyms:\n",
    "\n",
    "    word = pr.split(',')\n",
    "    c1 = word[0]\n",
    "    c2 = word[1]\n",
    "    \n",
    "    if c1 not in wordic or c2 not in wordic: continue\n",
    "\n",
    "    v1 = Vtr[wordic[c1]]\n",
    "    v2 = Vtr[wordic[c2]]\n",
    "    synDP.append([ np.dot(v1,v2), c1.encode('utf-8'), c2.encode('utf-8') ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in synonyms:\n",
    "    v1 = choice(Vtr)\n",
    "    v2 = choice(Vtr)\n",
    "    randDP.append(np.dot(v1,v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dir = './output'\n",
    "with codecs.open(\"{}/randdist_k={}.csv\".format(output_dir,k), 'w', encoding='utf-8') as f:\n",
    "    wr = csv.writer(f)\n",
    "    wr.writerows([[r] for r in randDP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open(\"{}/syndist_k={}.csv\".format(output_dir,k), 'w') as f:\n",
    "    wr = csv.writer(f)\n",
    "    wr.writerows(synDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# scrap chinese tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = nx.read_graphml('data/graphs/chinese_graph.graphml', unicode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = list(G.node[a]['chinese'] for a in G.node.keys() if 'chinese' in G.node[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url = \"https://www.chinesetools.eu/tools/synonym/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122689"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def url_encoding(data) :\n",
    "    tmp = ''\n",
    "    for i in xrange( len(data) ):\n",
    "        tmp = tmp + '&#' + str(ord(data[i])) + ';'\n",
    "    \n",
    "    return urllib.quote(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "若无其事\n"
     ]
    }
   ],
   "source": [
    "# for i, ch in enumerate(words):\n",
    "#     if len(ch) is 2:\n",
    "#         print i, ch\n",
    "# 46\n",
    "\n",
    "w = words[4]\n",
    "print w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不动声色\n",
      "处之泰然\n",
      "处变不惊\n",
      "守静\n",
      "定神\n",
      "宠辱不惊\n",
      "措置裕如\n",
      "毫不动摇\n",
      "沉住气\n",
      "沉着\n",
      "波澜不惊\n",
      "泰然处之\n",
      "泰然自若\n",
      "满不在乎\n",
      "熙和恬静\n",
      "稳如泰山\n",
      "行若无事\n",
      "见惯不惊\n",
      "谈笑自若\n",
      "镇定\n",
      "镇定自若\n",
      "镇静\n",
      "面不改色\n"
     ]
    }
   ],
   "source": [
    "syn_pairs = []\n",
    "query = base_url + '?q=' + url_encoding(w) + '&Submit=Search'\n",
    "r = urllib.urlopen(query)\n",
    "soup = BeautifulSoup(r)\n",
    "\n",
    "parse = soup.find_all('div', 'arrondi_10')\n",
    "\n",
    "# if ( len(parse) < 3 ):\n",
    "\n",
    "# find the 'divs' which contain the synonym \n",
    "divs = parse[1].find_all('div')\n",
    "\n",
    "inner_finder = 0\n",
    "\n",
    "for i, dv in enumerate(divs):\n",
    "    if dv.string == 'Click on the synonyms to see it on the Chinese dictionary:' :\n",
    "        inner_finder = i\n",
    "        \n",
    "for dv in divs[inner_finder + 1].find_all('div'):\n",
    "    for a in dv.find_all('a'):\n",
    "        print a.string\n",
    "        syn_pairs.append([w,a.string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open('chinesetools_synonym.csv','w', encoding='utf-8') as f:\n",
    "    for item in syn_pairs:\n",
    "        print item[0]\n",
    "        f.write(\"%s\\n\" % item[0])\n",
    "    #wr = csv.writer(f)\n",
    "    #wr.writerows(syn_pairs.encode('u'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import networkx as nx\n",
    "import codecs\n",
    "\n",
    "G = nx.read_graphml('data/graphs/chinese_graph.graphml', unicode)\n",
    "words = list(G.node[a]['chinese'] for a in G.node.keys() if 'chinese' in G.node[a])\n",
    "\n",
    "base_url = \"https://www.chinesetools.eu/tools/synonym/\"\n",
    "\n",
    "def url_encoding(data) :\n",
    "    tmp = ''\n",
    "    for i in xrange( len(data) ):\n",
    "        tmp = tmp + '&#' + str(ord(data[i])) + ';'\n",
    "    \n",
    "    return urllib.quote(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/122689] now processing: 萨里奇 , got 0 synonyms\n",
      "[1/122689] now processing: 布罗德里克 , got 0 synonyms\n",
      "[2/122689] now processing: 若干年 , got 0 synonyms\n",
      "[3/122689] now processing: 若干年内 , got 0 synonyms\n",
      "[4/122689] now processing: 若无其事 , got 0 synonyms\n",
      "若无其事 不动声色\n",
      "若无其事 处之泰然\n",
      "若无其事 处变不惊\n",
      "若无其事 守静\n",
      "若无其事 定神\n",
      "若无其事 宠辱不惊\n",
      "若无其事 措置裕如\n",
      "若无其事 毫不动摇\n",
      "若无其事 沉住气\n",
      "若无其事 沉着\n",
      "若无其事 波澜不惊\n",
      "若无其事 泰然处之\n",
      "若无其事 泰然自若\n",
      "若无其事 满不在乎\n",
      "若无其事 熙和恬静\n",
      "若无其事 稳如泰山\n",
      "若无其事 行若无事\n",
      "若无其事 见惯不惊\n",
      "若无其事 谈笑自若\n",
      "若无其事 镇定\n",
      "若无其事 镇定自若\n",
      "若无其事 镇静\n",
      "若无其事 面不改色\n",
      "[5/122689] now processing: 若有证据 , got 23 synonyms\n",
      "[6/122689] now processing: 若泽 , got 23 synonyms\n",
      "[7/122689] now processing: 若羌县 , got 23 synonyms\n",
      "[8/122689] now processing: 若许 , got 23 synonyms\n",
      "[9/122689] now processing: 若隐若现 , got 23 synonyms\n",
      "若隐若现 不明\n",
      "若隐若现 依稀\n",
      "若隐若现 幽渺\n",
      "若隐若现 影影绰绰\n",
      "若隐若现 微茫\n",
      "若隐若现 恍\n",
      "若隐若现 恍恍忽忽\n",
      "若隐若现 恍惚\n",
      "若隐若现 惺忪\n",
      "若隐若现 朦朦\n",
      "若隐若现 朦胧\n",
      "若隐若现 模模糊糊\n",
      "若隐若现 模糊\n",
      "若隐若现 模糊不清\n",
      "若隐若现 渺无音信\n",
      "若隐若现 渺茫\n",
      "若隐若现 白蒙蒙\n",
      "若隐若现 盲用\n",
      "若隐若现 盲目\n",
      "若隐若现 糊涂\n",
      "若隐若现 糊里糊涂\n",
      "若隐若现 缥缈\n",
      "若隐若现 胡里胡涂\n",
      "若隐若现 若明若暗\n",
      "若隐若现 莫明其妙\n",
      "若隐若现 莽苍\n",
      "若隐若现 蒙胧\n",
      "若隐若现 迷茫\n",
      "若隐若现 迷蒙\n",
      "若隐若现 隐约\n",
      "若隐若现 隐约可见\n",
      "若隐若现 隐隐\n",
      "若隐若现 隐隐约约\n",
      "若隐若现 雾里看花\n",
      "若隐若现 飘渺\n",
      "若隐若现 黑乎乎\n",
      "若隐若现 黑忽忽\n",
      "若隐若现 黑糊糊\n",
      "若隐若现 倬\n",
      "若隐若现 时隐时现\n",
      "若隐若现 昭\n",
      "若隐若现 语焉不详\n",
      "若隐若现 隐约\n",
      "若隐若现 隐隐\n",
      "若隐若现 隐隐约约\n",
      "[10/122689] now processing: 若雨文学网 , got 68 synonyms\n",
      "[11/122689] now processing: 苦兰加苦甙 , got 68 synonyms\n",
      "[12/122689] now processing: 萨里南 , got 68 synonyms\n",
      "[13/122689] now processing: 亚西尔 , got 68 synonyms\n",
      "[14/122689] now processing: 亚诺夫斯基 , got 68 synonyms\n",
      "[15/122689] now processing: 亚蓝闪石 , got 68 synonyms\n",
      "[16/122689] now processing: 亚行 , got 68 synonyms\n",
      "[17/122689] now processing: 亚莫林斯基 , got 68 synonyms\n",
      "[18/122689] now processing: 亚莫皂甙元 , got 68 synonyms\n",
      "[19/122689] now processing: 亚裔新血 , got 68 synonyms\n",
      "[20/122689] now processing: 亚西乌特 , got 68 synonyms\n",
      "[21/122689] now processing: 亚行行长 , got 68 synonyms\n",
      "[22/122689] now processing: 亚裔 , got 68 synonyms\n",
      "[23/122689] now processing: 遗照 , got 68 synonyms\n",
      "遗照 真影\n",
      "遗照 神像\n",
      "遗照 遗像\n",
      "遗照 遗容\n",
      "[24/122689] now processing: 遗漏 , got 72 synonyms\n",
      "遗漏 挂一漏万\n",
      "遗漏 漏\n",
      "遗漏 漏掉\n",
      "遗漏 疏漏\n",
      "遗漏 脱\n",
      "遗漏 脱漏\n",
      "遗漏 落\n",
      "[25/122689] now processing: 河 , got 79 synonyms\n",
      "河 地表水\n",
      "河 大江\n",
      "河 大溜\n",
      "河 天堑\n",
      "河 川\n",
      "河 延河水\n",
      "河 水\n",
      "河 水流\n",
      "河 江\n",
      "河 江河\n",
      "河 江河水\n",
      "河 江流\n",
      "河 江湖\n",
      "河 沧江\n",
      "河 河川\n",
      "河 河水\n",
      "河 河流\n",
      "河 河里\n",
      "河 沿河\n",
      "河 浊流\n",
      "河 淮\n",
      "河 长河\n",
      "[26/122689] now processing: 经济界 , got 101 synonyms\n",
      "[27/122689] now processing: 经济特区 , got 101 synonyms\n",
      "[28/122689] now processing: 经济潜力 , got 101 synonyms\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7e2216e9658a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_url\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'?q='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0murl_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'&Submit=Search'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dato/anaconda2/envs/tensorflow/lib/python2.7/urllib.pyc\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, proxies, context)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_urlopener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dato/anaconda2/envs/tensorflow/lib/python2.7/urllib.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dato/anaconda2/envs/tensorflow/lib/python2.7/urllib.pyc\u001b[0m in \u001b[0;36mopen_https\u001b[0;34m(self, url, data)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddheaders\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m             \u001b[0merrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetreply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m             \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrcode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dato/anaconda2/envs/tensorflow/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mgetreply\u001b[0;34m(self, buffering)\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m                 \u001b[0;31m#only add this keyword if non-default for compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dato/anaconda2/envs/tensorflow/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self, buffering)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwill_close\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_UNKNOWN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CS_IDLE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dato/anaconda2/envs/tensorflow/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dato/anaconda2/envs/tensorflow/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# Initialize with Simple-Response defaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dato/anaconda2/envs/tensorflow/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dato/anaconda2/envs/tensorflow/lib/python2.7/ssl.pyc\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                     self.__class__)\n\u001b[0;32m--> 756\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dato/anaconda2/envs/tensorflow/lib/python2.7/ssl.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    641\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "f = codecs.open('chinesetools_synonym.csv','w', encoding='utf-8')\n",
    "\n",
    "syn_pairs = []\n",
    "\n",
    "for i,w in enumerate(words):\n",
    "\n",
    "    print(\"[{}/{}] now processing: {} , got {} synonyms\"\n",
    "              .format(i,len(words), w.encode('utf-8'), len(syn_pairs)))        \n",
    "    \n",
    "    query = base_url + '?q=' + url_encoding(w) + '&Submit=Search'\n",
    "    r = urllib.urlopen(query)\n",
    "    soup = BeautifulSoup(r)\n",
    "\n",
    "    parse = soup.find_all('div', 'arrondi_10')\n",
    "\n",
    "    if ( len(parse) < 2 ):\n",
    "        continue\n",
    "\n",
    "    # find the 'divs' which contain the synonym \n",
    "    divs = parse[1].find_all('div')\n",
    "\n",
    "    inner_finder = -1\n",
    "\n",
    "    for i, dv in enumerate(divs):\n",
    "        if dv.string == 'Click on the synonyms to see it on the Chinese dictionary:' :\n",
    "            inner_finder = i\n",
    "\n",
    "    if inner_finder is -1:\n",
    "        continue\n",
    "            \n",
    "    for dv in divs[inner_finder + 1].find_all('div'):\n",
    "        for a in dv.find_all('a'):\n",
    "            print w, a.string.strip()\n",
    "            syn_pairs.append([w, a.string.strip()])\n",
    "            f.write(\"%s\\n\" % (w + ',' + a.string.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open('chinesetools_synonym.csv','w', encoding='utf-8') as f:\n",
    "    for item in syn_pairs:\n",
    "        print item[0]\n",
    "        f.write(\"%s\\n\" % item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "若无其事 面不改色\n"
     ]
    }
   ],
   "source": [
    "print w, a.string.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "syn_pairs.append([w, a.string.strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-77bfd674ebbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "kk = w + a.sring.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inner_finder = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import time\n",
    "from random import choice\n",
    "from math import log\n",
    "import codecs\n",
    "import csv\n",
    "import dato_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IS_CHINESE_TEST = True\n",
    "\n",
    "if IS_CHINESE_TEST:\n",
    "    G = nx.read_graphml('./data/graphs/chinese_graph.graphml', unicode) # Chinese graph\n",
    "else:\n",
    "    G = nx.read_graphml('graphs/bipartite_graph.graphml', unicode) # Korean language graph    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = nx.connected_component_subgraphs(G)\n",
    "G = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dato_utils.create_dir('result')\n",
    "output_dir = \"./result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sts = nx.bipartite.sets(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117116"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = None\n",
    "hanjas = None\n",
    "wordSet = None\n",
    "if len(sts[0]) > 6000: \n",
    "    words = list(sts[0])\n",
    "    wordSet = sts[0]\n",
    "    hanjas = list(sts[1])   # root\n",
    "else: \n",
    "    words = list(sts[1])\n",
    "    wordSet = sts[1]\n",
    "    hanjas = list(sts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordic = {G.node[e]['chinese']:k for k,e in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synonyms = None\n",
    "# synonyms delimeter = ',' \n",
    "if IS_CHINESE_TEST:\n",
    "    with codecs.open('./data/synonyms/chinesetools_synonyms.csv', 'r', encoding='utf-8') as f:\n",
    "        synonyms = [line.strip() for line in f]\n",
    "        \n",
    "else:\n",
    "    with codecs.open('./data/synonums/korean_synonyms.csv', 'r', encoding='utf-8') as f:\n",
    "        synonyms = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "妪,老太婆\n"
     ]
    }
   ],
   "source": [
    "print synonyms[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synDP = []\n",
    "randDP = []\n",
    "\n",
    "A = nx.bipartite.biadjacency_matrix(G, hanjas)\n",
    "#A = A.asfptype()\n",
    "#A = A.tolil()\n",
    "A = A.astype(float)\n",
    "weight = False # In case we chose not to do TF-IDF weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minK = 100\n",
    "maxK = 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorizing for k=500\n"
     ]
    }
   ],
   "source": [
    "k = 500\n",
    "print(\"Factorizing for k={}\".format(k))\n",
    "U,s,V = sp.sparse.linalg.svds(A, k)\n",
    "Vtr = V.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "赃,贼赃\n"
     ]
    }
   ],
   "source": [
    "for _ in synonyms:\n",
    "    print _\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = synonyms[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = aa.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = Vtr[wordic[c[0]]]\n",
    "v2 = Vtr[wordic[c[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.002946969290243294"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(v1, v2)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0592178303158552e-05"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statistics import stdev\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: './result/randdist_k=400.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5342fe7e3f8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mhomDir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./result'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/randdist_k={}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhomDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mranDist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mranDist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mranDist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: './result/randdist_k=400.csv'"
     ]
    }
   ],
   "source": [
    "synDist = None\n",
    "ranDist = None\n",
    "\n",
    "dim = 400\n",
    "\n",
    "missRand = []\n",
    "gotSyn = []\n",
    "ks = []\n",
    "\n",
    "homDir = './result'\n",
    "\n",
    "with open('{}/randdist_k={}.csv'.format(homDir, dim)) as f:\n",
    "    ranDist = list(csv.reader(f))\n",
    "    ranDist = [float(a[0]) for a in ranDist]\n",
    "\n",
    "with open('{}/syndist_k={}.csv'.format(homDir, dim)) as f:\n",
    "    synDist = list(csv.reader(f))\n",
    "    synDist = [float(a[0]) for a in synDist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sd = stdev(ranDist)\n",
    "ks.append(dim)\n",
    "missRand.append(sum(1.0 if abs(rd) > sd else 0.0 for rd in ranDist)/len(ranDist))\n",
    "gotSyn.append(sum(1.0 if abs(rd) > sd else 0.0 for rd in synDist)/len(synDist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.027351117251228237]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missRand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03417677542630497]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gotSyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = nx.read_graphml('./data/graphs/chinese_graph.graphml', unicode) # Chinese graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sts = nx.bipartite.sets(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = list(sts[0]) + list(sts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open('./data/synonyms/chinesetools_synonyms.csv', 'r', encoding='utf-8') as f:\n",
    "        synonyms = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\\u8d43,\\u8d3c\\u8d43'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
